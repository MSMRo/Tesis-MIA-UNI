{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5cbae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NSR': array([[-0.06451476, -0.05951476, -0.02951476, ...,  0.13548524,\n",
       "          0.13048524,  0.11548524],\n",
       "        [ 0.24548524,  0.25048524,  0.24048524, ...,  0.34048524,\n",
       "          0.33548524,  0.31548524],\n",
       "        [ 0.13048524,  0.12548524,  0.11048524, ..., -0.20451476,\n",
       "         -0.20451476, -0.20451476],\n",
       "        ...,\n",
       "        [-0.46451476, -0.46451476, -0.46451476, ..., -0.59451476,\n",
       "         -0.58951476, -0.58951476],\n",
       "        [-0.53451476, -0.51451476, -0.53451476, ..., -0.51451476,\n",
       "         -0.44451476, -0.40451476],\n",
       "        [ 0.51548524,  0.50548524,  0.50548524, ...,  0.21048524,\n",
       "          0.20048524,  0.18548524]]),\n",
       " 'VT': array([[ 0.10787069,  0.08787069,  0.08787069, ...,  0.01287069,\n",
       "         -0.00212931,  0.01787069],\n",
       "        [-0.31212931, -0.29712931, -0.27212931, ...,  0.82787069,\n",
       "          0.84787069,  0.86787069],\n",
       "        [ 0.01287069,  0.00787069,  0.00287069, ...,  0.04787069,\n",
       "          0.06787069,  0.10287069],\n",
       "        ...,\n",
       "        [ 0.17287069,  0.16787069,  0.16287069, ..., -0.08212931,\n",
       "         -0.06712931, -0.07212931],\n",
       "        [-0.23712931, -0.22712931, -0.21712931, ...,  1.69287069,\n",
       "          1.68787069,  1.63287069],\n",
       "        [ 0.14787069,  0.17787069,  0.20787069, ..., -0.01212931,\n",
       "         -0.01212931, -0.01212931]]),\n",
       " 'IVR': array([[ 0.05063069,  0.04563069,  0.04063069, ..., -0.10936931,\n",
       "         -0.11436931, -0.11436931],\n",
       "        [ 0.19063069,  0.20063069,  0.19563069, ..., -0.02436931,\n",
       "         -0.02436931, -0.00936931],\n",
       "        [ 0.02063069,  0.02563069,  0.03063069, ...,  0.23563069,\n",
       "          0.26563069,  0.28063069],\n",
       "        ...,\n",
       "        [-0.02436931, -0.01936931, -0.03436931, ...,  0.07063069,\n",
       "          0.08563069,  0.07063069],\n",
       "        [ 0.73563069,  0.74563069,  0.68063069, ..., -0.08936931,\n",
       "         -0.08936931, -0.09436931],\n",
       "        [ 0.11063069,  0.12063069,  0.12063069, ...,  0.35563069,\n",
       "          0.39063069,  0.45063069]]),\n",
       " 'VFL': array([[-0.05835083, -0.01835083,  0.00664917, ...,  0.12164917,\n",
       "          0.12164917,  0.14664917],\n",
       "        [-0.14335083, -0.13335083, -0.12335083, ..., -0.03335083,\n",
       "         -0.02335083,  0.01164917],\n",
       "        [ 0.01664917,  0.02664917,  0.03164917, ..., -0.16335083,\n",
       "         -0.16835083, -0.15335083],\n",
       "        ...,\n",
       "        [-0.04835083, -0.04835083, -0.03335083, ...,  0.08164917,\n",
       "          0.09664917,  0.12664917],\n",
       "        [ 0.39164917,  0.41664917,  0.44664917, ...,  0.06664917,\n",
       "          0.04164917,  0.03164917],\n",
       "        [ 0.03664917,  0.07664917,  0.12664917, ...,  0.17664917,\n",
       "          0.16664917,  0.17164917]]),\n",
       " 'Fusion': array([[ 0.24582967,  0.26082967,  0.25082967, ...,  0.18082967,\n",
       "          0.17582967,  0.19082967],\n",
       "        [-1.14417033, -1.15417033, -1.17417033, ...,  0.31082967,\n",
       "          0.31082967,  0.30582967],\n",
       "        [ 0.20582967,  0.19082967,  0.19582967, ...,  0.18082967,\n",
       "          0.17082967,  0.14582967],\n",
       "        ...,\n",
       "        [-0.23917033, -0.23917033, -0.22917033, ..., -0.20917033,\n",
       "         -0.21917033, -0.22917033],\n",
       "        [ 0.15082967,  0.09082967,  0.04582967, ..., -0.57417033,\n",
       "         -0.56417033, -0.57417033],\n",
       "        [-0.59417033, -0.55417033, -0.50917033, ...,  1.81582967,\n",
       "          1.91082967,  2.01582967]]),\n",
       " 'LBBBB': array([[-0.09205654, -0.09705654, -0.09705654, ..., -0.00705654,\n",
       "         -0.00205654, -0.00705654],\n",
       "        [-0.03205654, -0.03205654, -0.00705654, ...,  0.03294346,\n",
       "          0.03794346,  0.04294346],\n",
       "        [-0.00205654, -0.00205654, -0.01705654, ..., -0.19205654,\n",
       "         -0.19705654, -0.17705654],\n",
       "        ...,\n",
       "        [-0.48705654, -0.52705654, -0.55705654, ..., -0.30705654,\n",
       "         -0.41705654, -0.51705654],\n",
       "        [-0.31705654, -0.33705654, -0.33705654, ...,  0.12794346,\n",
       "          0.15794346,  0.15794346],\n",
       "        [-0.02205654, -0.01205654, -0.00705654, ..., -0.10205654,\n",
       "         -0.07705654, -0.05705654]]),\n",
       " 'RBBBB': array([[ 0.66243907,  0.61743907,  0.57743907, ...,  1.21243907,\n",
       "          0.76743907,  0.40243907],\n",
       "        [-0.47756093, -0.44256093, -0.44256093, ..., -0.56256093,\n",
       "         -0.57256093, -0.56756093],\n",
       "        [ 1.89243907,  1.81243907,  1.69243907, ..., -0.25756093,\n",
       "         -0.25756093, -0.26256093],\n",
       "        ...,\n",
       "        [-0.08756093, -0.08756093, -0.09756093, ..., -0.30756093,\n",
       "         -0.30756093, -0.29756093],\n",
       "        [ 1.33743907,  0.85243907,  0.36743907, ...,  0.47743907,\n",
       "          0.48743907,  0.50243907],\n",
       "        [ 0.38243907,  0.37243907,  0.39243907, ...,  0.35243907,\n",
       "          0.38243907,  0.40743907]]),\n",
       " 'SDHB': array([[-0.1526725, -0.1526725, -0.1426725, ..., -0.0726725, -0.0776725,\n",
       "         -0.0676725],\n",
       "        [ 0.0623275,  0.0773275,  0.0523275, ..., -0.1826725, -0.1776725,\n",
       "         -0.1676725],\n",
       "        [-0.0726725, -0.0676725, -0.0576725, ..., -0.1076725, -0.1226725,\n",
       "         -0.1276725],\n",
       "        ...,\n",
       "        [-0.0126725, -0.0176725, -0.0226725, ..., -0.0426725, -0.0226725,\n",
       "         -0.0076725],\n",
       "        [ 0.0023275,  0.0023275,  0.0073275, ...,  0.1673275,  0.1723275,\n",
       "          0.1823275],\n",
       "        [-0.0826725, -0.0926725, -0.0926725, ..., -0.0976725, -0.1026725,\n",
       "         -0.1176725]]),\n",
       " 'PR': array([[ 0.4307984,  0.3857984,  0.3457984, ...,  0.8807984,  0.8957984,\n",
       "          0.9307984],\n",
       "        [ 0.3407984,  0.3557984,  0.3607984, ...,  1.3157984,  1.5207984,\n",
       "          1.4657984],\n",
       "        [-0.0842016, -0.0942016, -0.1042016, ..., -0.1142016, -0.0842016,\n",
       "         -0.0692016],\n",
       "        ...,\n",
       "        [ 0.3957984,  0.3707984,  0.3457984, ..., -0.5142016, -0.4242016,\n",
       "         -0.3242016],\n",
       "        [ 0.2857984,  0.3107984,  0.3107984, ..., -1.6792016, -1.7642016,\n",
       "         -1.8242016],\n",
       "        [ 0.9507984,  0.9907984,  1.0107984, ..., -1.5492016, -1.4492016,\n",
       "         -1.3642016]]),\n",
       " 'APB': array([[-0.00630398, -0.02630398, -0.01630398, ..., -0.25130398,\n",
       "         -0.25630398, -0.25630398],\n",
       "        [-0.21130398, -0.20630398, -0.21630398, ...,  0.29369602,\n",
       "          0.52369602,  0.77369602],\n",
       "        [-0.12630398, -0.13130398, -0.14630398, ..., -0.22630398,\n",
       "         -0.23630398, -0.23630398],\n",
       "        ...,\n",
       "        [ 0.17369602,  0.16369602,  0.15869602, ...,  0.03869602,\n",
       "          0.01869602, -0.00130398],\n",
       "        [-0.08130398, -0.09630398, -0.10130398, ..., -0.15630398,\n",
       "         -0.15630398, -0.16130398],\n",
       "        [-0.04630398, -0.05630398, -0.06630398, ..., -0.11630398,\n",
       "         -0.12130398, -0.12130398]]),\n",
       " 'AFL': array([[-0.02385639, -0.00885639,  0.01614361, ...,  0.02614361,\n",
       "          0.01614361,  0.00114361],\n",
       "        [ 0.12614361,  0.09614361,  0.11114361, ...,  0.76614361,\n",
       "          0.84114361,  0.85114361],\n",
       "        [-0.06885639, -0.09385639, -0.08885639, ..., -0.17385639,\n",
       "         -0.17885639, -0.17385639],\n",
       "        ...,\n",
       "        [-0.20385639, -0.23885639, -0.24385639, ...,  0.05114361,\n",
       "          0.05614361,  0.04114361],\n",
       "        [-0.19885639, -0.19885639, -0.19385639, ..., -0.26885639,\n",
       "         -0.26885639, -0.28885639],\n",
       "        [-0.00385639,  0.01114361,  0.01614361, ..., -0.18385639,\n",
       "         -0.18885639, -0.18385639]]),\n",
       " 'AFIB': array([[ 0.45437483,  0.57937483,  0.71937483, ..., -0.10562517,\n",
       "         -0.09062517, -0.09062517],\n",
       "        [ 0.91937483,  0.59437483,  0.34937483, ..., -0.12562517,\n",
       "         -0.11062517, -0.10562517],\n",
       "        [-0.08562517, -0.09062517, -0.07562517, ..., -0.08062517,\n",
       "         -0.07062517, -0.06062517],\n",
       "        ...,\n",
       "        [-0.22562517, -0.21062517, -0.19562517, ..., -0.07562517,\n",
       "         -0.09062517, -0.12062517],\n",
       "        [-0.02562517, -0.04562517, -0.04562517, ..., -0.13062517,\n",
       "         -0.11562517, -0.11562517],\n",
       "        [ 0.30937483,  0.31437483,  0.31437483, ...,  0.12437483,\n",
       "          0.12437483,  0.13937483]]),\n",
       " 'SVTA': array([[-0.09665128, -0.11165128, -0.14165128, ..., -0.12165128,\n",
       "         -0.12665128, -0.11665128],\n",
       "        [-0.13665128, -0.10665128, -0.08665128, ...,  0.00334872,\n",
       "          0.00834872,  0.00334872],\n",
       "        [-0.13165128, -0.07665128, -0.05665128, ..., -0.14165128,\n",
       "         -0.12165128, -0.12165128],\n",
       "        ...,\n",
       "        [-0.86665128, -0.86665128, -0.81665128, ...,  0.21834872,\n",
       "          0.23334872,  0.26334872],\n",
       "        [ 0.09334872,  0.11834872,  0.15334872, ...,  0.08334872,\n",
       "          0.08834872,  0.07334872],\n",
       "        [ 0.32334872,  0.29834872,  0.29834872, ..., -0.07165128,\n",
       "         -0.08165128, -0.08665128]]),\n",
       " 'WPW': array([[ 0.03522831,  0.04022831,  0.05022831, ...,  0.13022831,\n",
       "          0.13522831,  0.12522831],\n",
       "        [-0.20477169, -0.21977169, -0.22977169, ...,  1.58022831,\n",
       "          1.62022831,  1.58022831],\n",
       "        [ 1.46522831,  1.27522831,  1.00522831, ...,  0.35022831,\n",
       "          0.32022831,  0.30522831],\n",
       "        ...,\n",
       "        [-0.13477169, -0.12977169, -0.10977169, ...,  0.00522831,\n",
       "         -0.00477169, -0.00477169],\n",
       "        [-0.12977169, -0.12977169, -0.13977169, ..., -0.10477169,\n",
       "         -0.09477169, -0.08477169],\n",
       "        [ 0.07022831,  0.04022831,  0.03522831, ..., -0.14477169,\n",
       "         -0.13477169, -0.11477169]]),\n",
       " 'PVC': array([[ 0.14564412,  0.14564412,  0.14064412, ...,  0.41064412,\n",
       "          0.43064412,  0.46064412],\n",
       "        [-1.06435588, -1.06935588, -1.05435588, ..., -1.09435588,\n",
       "         -1.08935588, -1.09935588],\n",
       "        [ 0.10564412,  0.09064412,  0.07064412, ...,  0.16064412,\n",
       "          0.16564412,  0.17064412],\n",
       "        ...,\n",
       "        [-0.06435588, -0.05435588, -0.05435588, ...,  0.26564412,\n",
       "          0.28064412,  0.29064412],\n",
       "        [-0.08435588, -0.08435588, -0.08435588, ..., -0.17935588,\n",
       "         -0.19935588, -0.18435588],\n",
       "        [ 0.22564412,  0.23564412,  0.22564412, ..., -0.71435588,\n",
       "         -0.70435588, -0.68935588]]),\n",
       " 'Bigeminy': array([[-0.11918164, -0.11918164, -0.11918164, ..., -0.28918164,\n",
       "         -0.28418164, -0.26918164],\n",
       "        [-0.27918164, -0.28418164, -0.26418164, ...,  0.88581836,\n",
       "          1.01081836,  1.12581836],\n",
       "        [ 0.61581836,  0.47081836,  0.37581836, ...,  0.33081836,\n",
       "          0.35581836,  0.38581836],\n",
       "        ...,\n",
       "        [ 0.62081836,  0.62081836,  0.62081836, ...,  0.18081836,\n",
       "          0.16081836,  0.14081836],\n",
       "        [-0.43918164, -0.44418164, -0.44918164, ..., -0.37918164,\n",
       "         -0.37418164, -0.37918164],\n",
       "        [-0.57918164, -0.53418164, -0.47918164, ..., -0.13918164,\n",
       "         -0.11418164, -0.09418164]]),\n",
       " 'Trigeminy': array([[ 0.21956848,  0.22456848,  0.21956848, ...,  0.19956848,\n",
       "          0.18956848,  0.19456848],\n",
       "        [-0.40543152, -0.40043152, -0.40543152, ..., -0.54543152,\n",
       "         -0.54543152, -0.54543152],\n",
       "        [ 0.10456848,  0.09456848,  0.08456848, ...,  0.06956848,\n",
       "          0.08456848,  0.08956848],\n",
       "        ...,\n",
       "        [ 0.05456848,  0.05456848,  0.03956848, ...,  0.11956848,\n",
       "          0.12956848,  0.12956848],\n",
       "        [ 0.08956848,  0.07956848,  0.06956848, ...,  0.08956848,\n",
       "          0.08956848,  0.08456848],\n",
       "        [ 0.21956848,  0.21456848,  0.23456848, ...,  0.06956848,\n",
       "          0.07456848,  0.06956848]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "path_db = \"../../ECG_DATASET/dataset_ekg.pkl\"\n",
    "\n",
    "with open(path_db, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "440eabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 1800)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset = dataset['NSR'][:,: dataset[\"NSR\"].shape[1]//2]\n",
    "\n",
    "X_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b586ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_dataset.shape[1]\n",
    "\n",
    "fs = 360\n",
    "ts = 1/fs\n",
    "t = np.arange(N)*ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a405f8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original range: [-2.155, 3.040]\n",
      "Normalized range: [-1.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# Normalizar al rango [-1, 1] para coincidir con Tanh\n",
    "X_min = X_dataset.min()\n",
    "X_max = X_dataset.max()\n",
    "X_dataset_normalized = 2 * (X_dataset - X_min) / (X_max - X_min) - 1\n",
    "\n",
    "print(f\"Original range: [{X_min:.3f}, {X_max:.3f}]\")\n",
    "print(f\"Normalized range: [{X_dataset_normalized.min():.3f}, {X_dataset_normalized.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e4d69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 2025\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "class SineWaveDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "\n",
    "def get_dataloader(data, batch_size=32, shuffle=True):\n",
    "    dataset = SineWaveDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce40fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== IMPROVED GAN ARCHITECTURE FOR ECG SIGNALS ==========\n",
    "# Using 1D Convolutional layers for better temporal pattern learning\n",
    "\n",
    "def weights_init(m):\n",
    "    \"\"\"Weight initialization for convolutional and linear layers\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# ========== GENERATOR: 1D CNN ARCHITECTURE ==========\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator using 1D transposed convolutions for temporal signal generation\"\"\"\n",
    "    def __init__(self, noise_dim=100, output_length=3600):\n",
    "        super().__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.output_length = output_length\n",
    "        \n",
    "        # Calculate initial feature map size\n",
    "        # We'll upsample: 225 -> 450 -> 900 -> 1800 -> 3600\n",
    "        self.init_size = output_length // 16  # 3600 // 16 = 225\n",
    "        \n",
    "        # Project noise to initial feature map\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256 * self.init_size),\n",
    "            nn.BatchNorm1d(256 * self.init_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Transposed convolutions for upsampling\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # 225 -> 450\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 450 -> 900\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 900 -> 1800\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 1800 -> 3600\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Final refinement layer\n",
    "            nn.Conv1d(16, 1, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Project and reshape\n",
    "        x = self.fc(z)\n",
    "        x = x.view(-1, 256, self.init_size)\n",
    "        # Generate signal\n",
    "        x = self.conv_blocks(x)\n",
    "        return x.squeeze(1)  # Remove channel dimension\n",
    "\n",
    "# ========== DISCRIMINATOR: 1D CNN ARCHITECTURE ==========\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator using 1D convolutions for temporal pattern recognition\"\"\"\n",
    "    def __init__(self, input_length=3600):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # 3600 -> 1800\n",
    "            nn.Conv1d(1, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 1800 -> 900\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 900 -> 450\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 450 -> 225\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        \n",
    "        # Calculate flattened size: 256 channels * 225 length\n",
    "        flattened_size = 256 * (input_length // 16)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add channel dimension if needed\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ========== SPECTRAL NORMALIZATION DISCRIMINATOR (Alternative) ==========\n",
    "class SpectralNormDiscriminator(nn.Module):\n",
    "    \"\"\"Discriminator with Spectral Normalization for stability\"\"\"\n",
    "    def __init__(self, input_length=3600):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # 3600 -> 1800\n",
    "            nn.utils.spectral_norm(nn.Conv1d(1, 64, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            # 1800 -> 900\n",
    "            nn.utils.spectral_norm(nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            # 900 -> 450\n",
    "            nn.utils.spectral_norm(nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            # 450 -> 225\n",
    "            nn.utils.spectral_norm(nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        \n",
    "        # Calculate flattened size: 512 channels * 225 length\n",
    "        flattened_size = 512 * (input_length // 16)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Linear(flattened_size, 1))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a687c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Training samples: 283\n",
      "Signal length: 1800\n",
      "Using Spectral Normalization Discriminator\n",
      "Input length to discriminator: 1792\n",
      "Actual flattened size: 57344\n",
      "Note: Data will be interpolated from 1800 to 1792\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x115200 and 57344x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m real_data.size(-\u001b[32m1\u001b[39m) != adjusted_output_dim:\n\u001b[32m    190\u001b[39m     real_data = F.interpolate(real_data, size=adjusted_output_dim, mode=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m d_loss, g_loss, w_d, gp = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m epoch_d_loss.append(d_loss)\n\u001b[32m    193\u001b[39m epoch_g_loss.append(g_loss \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(g_loss, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g_loss.item())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mWGANGPTrainer.train_step\u001b[39m\u001b[34m(self, real_data)\u001b[39m\n\u001b[32m     52\u001b[39m noise = torch.randn(batch_size, noise_dim).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     53\u001b[39m fake_data = \u001b[38;5;28mself\u001b[39m.generator(noise)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m d_fake = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.mean()\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Gradient penalty\u001b[39;00m\n\u001b[32m     57\u001b[39m gp = compute_gradient_penalty(\u001b[38;5;28mself\u001b[39m.discriminator, real_data, fake_data, \u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 150\u001b[39m, in \u001b[36mSpectralNormDiscriminator.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    148\u001b[39m x = \u001b[38;5;28mself\u001b[39m.conv_blocks(x)\n\u001b[32m    149\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-wsl2-conda-env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (64x115200 and 57344x1)"
     ]
    }
   ],
   "source": [
    "# ========== WGAN-GP TRAINER ==========\n",
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples, device):\n",
    "    \"\"\"Calculates the gradient penalty for WGAN-GP\"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    alpha = torch.rand(batch_size, 1).to(device)\n",
    "    \n",
    "    # Interpolated samples\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "    \n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    \n",
    "    fake = torch.ones(batch_size, 1).to(device)\n",
    "    \n",
    "    # Get gradients\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "class WGANGPTrainer:\n",
    "    \"\"\"Wasserstein GAN with Gradient Penalty trainer\"\"\"\n",
    "    def __init__(self, generator, discriminator, g_optimizer, d_optimizer, device, \n",
    "                 lambda_gp=10, n_critic=5):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.device = device\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.n_critic = n_critic\n",
    "        self.d_steps = 0\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = real_data.size(0)\n",
    "        real_data = real_data.to(self.device)\n",
    "\n",
    "        # ===== Train Discriminator =====\n",
    "        self.d_optimizer.zero_grad()\n",
    "\n",
    "        # Real samples\n",
    "        d_real = self.discriminator(real_data).mean()\n",
    "\n",
    "        # Fake samples\n",
    "        noise = torch.randn(batch_size, noise_dim).to(self.device)\n",
    "        fake_data = self.generator(noise)\n",
    "        d_fake = self.discriminator(fake_data.detach()).mean()\n",
    "\n",
    "        # Gradient penalty\n",
    "        gp = compute_gradient_penalty(self.discriminator, real_data, fake_data, self.device)\n",
    "\n",
    "        # Wasserstein loss with gradient penalty\n",
    "        d_loss = d_fake - d_real + self.lambda_gp * gp\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "\n",
    "        self.d_steps += 1\n",
    "\n",
    "        # ===== Train Generator (every n_critic steps) =====\n",
    "        g_loss = torch.tensor(0.0)\n",
    "        if self.d_steps % self.n_critic == 0:\n",
    "            self.g_optimizer.zero_grad()\n",
    "            noise = torch.randn(batch_size, noise_dim).to(self.device)\n",
    "            fake_data = self.generator(noise)\n",
    "            g_loss = -self.discriminator(fake_data).mean()  # Maximize D(G(z))\n",
    "            g_loss.backward()\n",
    "            self.g_optimizer.step()\n",
    "\n",
    "        # Return Wasserstein distance and generator loss\n",
    "        wasserstein_d = (d_real - d_fake).item()\n",
    "        return d_loss.item(), g_loss.item(), wasserstein_d, gp.item()\n",
    "\n",
    "# ========== HYPERPARAMETERS ==========\n",
    "noise_dim = 100\n",
    "batch_size = 64\n",
    "output_dim = X_dataset_normalized.shape[1]\n",
    "discriminator_type = 'spectral'  # Options: 'spectral' or 'standard'\n",
    "\n",
    "# ========== MODEL INITIALIZATION ==========\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Training samples: {X_dataset_normalized.shape[0]}\")\n",
    "print(f\"Signal length: {output_dim}\")\n",
    "\n",
    "# Adjust output_dim to be compatible with the generator architecture\n",
    "# The generator uses 4 ConvTranspose1d layers with stride=2, which multiplies by 16\n",
    "# Starting from initial_length = 112, we get 112 * 2^4 = 1792\n",
    "# We need to pad or adjust to get 1800\n",
    "adjusted_output_dim = 1792  # This is what the current architecture produces\n",
    "\n",
    "# Initialize generator\n",
    "# Note: The Generator class should produce adjusted_output_dim length signals\n",
    "# If Generator doesn't accept output_dim, it should be designed to produce the correct length\n",
    "generator = Generator(noise_dim=noise_dim).to(device)\n",
    "\n",
    "# Calculate the correct flattened size after conv layers\n",
    "# After 4 Conv1d layers with stride=2: 1792 -> 896 -> 448 -> 224 -> 112\n",
    "# With 512 channels: 112 * 512 = 57344\n",
    "if discriminator_type == 'spectral':\n",
    "    # Recreate discriminator with correct flattened size\n",
    "    discriminator = SpectralNormDiscriminator(input_length=adjusted_output_dim).to(device)\n",
    "    # Force recreation of FC layer with correct input size\n",
    "    test_input = torch.randn(1, 1, adjusted_output_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        conv_output = discriminator.conv_blocks(test_input)\n",
    "        actual_flattened_size = conv_output.view(1, -1).shape[1]\n",
    "    # Recreate FC layer with correct size\n",
    "    discriminator.fc = torch.nn.Sequential(\n",
    "        torch.nn.utils.spectral_norm(torch.nn.Linear(actual_flattened_size, 1))\n",
    "    ).to(device)\n",
    "    print(\"Using Spectral Normalization Discriminator\")\n",
    "    print(f\"Input length to discriminator: {adjusted_output_dim}\")\n",
    "    print(f\"Actual flattened size: {actual_flattened_size}\")\n",
    "    print(f\"Note: Data will be interpolated from {output_dim} to {adjusted_output_dim}\")\n",
    "else:\n",
    "    discriminator = Discriminator(input_length=adjusted_output_dim).to(device)\n",
    "    # Fix FC layer for standard discriminator too\n",
    "    test_input = torch.randn(1, 1, adjusted_output_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        conv_output = discriminator.conv_blocks(test_input)\n",
    "        actual_flattened_size = conv_output.view(1, -1).shape[1]\n",
    "    discriminator.fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(actual_flattened_size, 1)\n",
    "    ).to(device)\n",
    "    print(\"Using Standard Discriminator\")\n",
    "    print(f\"Input length to discriminator: {adjusted_output_dim}\")\n",
    "    print(f\"Actual flattened size: {actual_flattened_size}\")\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "# ========== OPTIMIZERS ==========\n",
    "# WGAN-GP typically uses Adam with specific hyperparameters\n",
    "g_optimizer = Adam(generator.parameters(), lr=0.0001, betas=(0.0, 0.9))\n",
    "d_optimizer = Adam(discriminator.parameters(), lr=0.0001, betas=(0.0, 0.9))\n",
    "\n",
    "# ========== TRAINER SETUP ==========\n",
    "trainer = WGANGPTrainer(\n",
    "    generator, discriminator, \n",
    "    g_optimizer, d_optimizer, \n",
    "    device, \n",
    "    lambda_gp=10,  # Gradient penalty coefficient\n",
    "    n_critic=5     # Train discriminator 5 times per generator update\n",
    ")\n",
    "\n",
    "# ========== TRAINING LOOP ==========\n",
    "num_epochs = 2000\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "w_distances = []\n",
    "gp_values = []\n",
    "\n",
    "# Interpolate data to match generator output size\n",
    "import torch.nn.functional as F\n",
    "X_dataset_adjusted = F.interpolate(\n",
    "    torch.tensor(X_dataset_normalized).unsqueeze(1), \n",
    "    size=adjusted_output_dim, \n",
    "    mode='linear', \n",
    "    align_corners=False\n",
    ").squeeze(1).numpy()\n",
    "\n",
    "# Use adjusted data\n",
    "dataloader_normalized = get_dataloader(X_dataset_adjusted, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "EPOCHS_TO_PLOT = 200\n",
    "LOSS_MAX_VIEW = batch_size * EPOCHS_TO_PLOT\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss = []\n",
    "    epoch_g_loss = []\n",
    "    epoch_wd = []\n",
    "    epoch_gp = []\n",
    "    \n",
    "    for real_data in dataloader_normalized:\n",
    "        # Ensure real_data has correct shape (batch, 1, adjusted_output_dim)\n",
    "        if real_data.dim() == 2:\n",
    "            real_data = real_data.unsqueeze(1)\n",
    "        elif real_data.dim() == 3 and real_data.size(1) != 1:\n",
    "            # If shape is (batch, seq_len, channels), transpose to (batch, channels, seq_len)\n",
    "            real_data = real_data.transpose(1, 2)\n",
    "        # Always ensure the size matches adjusted_output_dim\n",
    "        if real_data.size(-1) != adjusted_output_dim:\n",
    "            real_data = F.interpolate(real_data, size=adjusted_output_dim, mode='linear', align_corners=False)\n",
    "        d_loss, g_loss, w_d, gp = trainer.train_step(real_data)\n",
    "        epoch_d_loss.append(d_loss)\n",
    "        epoch_g_loss.append(g_loss if isinstance(g_loss, float) else g_loss.item())\n",
    "        epoch_wd.append(w_d)\n",
    "        epoch_gp.append(gp)\n",
    "    \n",
    "    # Store average losses per epoch\n",
    "    d_losses.append(np.mean(epoch_d_loss))\n",
    "    g_losses.append(np.mean(epoch_g_loss))\n",
    "    w_distances.append(np.mean(epoch_wd))\n",
    "    gp_values.append(np.mean(epoch_gp))\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'  D Loss: {d_losses[-1]:.4f} | G Loss: {g_losses[-1]:.4f}')\n",
    "        print(f'  Wasserstein Distance: {w_distances[-1]:.4f} | GP: {gp_values[-1]:.4f}')\n",
    "\n",
    "    # Plot progress\n",
    "    if (epoch+1) % EPOCHS_TO_PLOT == 0:\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            # Generate multiple samples\n",
    "            noise = torch.randn(3, noise_dim).to(device)\n",
    "            generated_samples = generator(noise).cpu().numpy()\n",
    "        # Plot real sample for comparison (interpolate t to match adjusted length)\n",
    "        plt.subplot(4, 2, 4)\n",
    "        t_adjusted = np.linspace(0, t[-1], adjusted_output_dim)\n",
    "        # Denormalize generated samples\n",
    "        generated_samples_denorm = generated_samples * (X_max - X_min) + X_min\n",
    "        \n",
    "        # Plot generated samples\n",
    "        for i in range(3):\n",
    "            plt.subplot(4, 2, i+1)\n",
    "            t_adjusted = np.linspace(0, t[-1], adjusted_output_dim)\n",
    "            plt.plot(t_adjusted, generated_samples_denorm[i], color='blue', alpha=0.7, linewidth=0.8)\n",
    "            plt.xlabel('Time [s]')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.title(f'Generated Sample {i+1} - Epoch {epoch+1}')\n",
    "            plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Plot real sample for comparison (interpolate t to match adjusted length)\n",
    "        plt.subplot(4, 2, 4)\n",
    "        t_adjusted = np.linspace(0, t[-1], adjusted_output_dim)\n",
    "        plt.plot(t_adjusted, X_dataset_adjusted[np.random.randint(0, X_dataset_adjusted.shape[0])], color='green', alpha=0.7, linewidth=0.8)\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('Real ECG Sample (Interpolated)')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.plot(d_losses, label='D Loss', alpha=0.7)\n",
    "        plt.plot(g_losses, label='G Loss', alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Losses')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        # Plot Wasserstein distance\n",
    "        plt.subplot(4, 2, 6)\n",
    "        # Frequency domain comparison\n",
    "        plt.subplot(4, 2, 8)\n",
    "        from scipy.fft import fft, fftfreq\n",
    "        # Plot gradient penalty\n",
    "        plt.subplot(4, 2, 7)\n",
    "        plt.plot(gp_values, color='red', alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Gradient Penalty')\n",
    "        plt.title('Gradient Penalty')\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        # Frequency domain comparison\n",
    "        plt.subplot(4, 2, 8)\n",
    "        from scipy.fft import fft, fftfreq\n",
    "        # Use adjusted data for FFT comparison\n",
    "        fft_real = np.abs(fft(X_dataset_adjusted[0]))[:adjusted_output_dim//2]\n",
    "        fft_gen = np.abs(fft(generated_samples_denorm[0]))[:adjusted_output_dim//2]\n",
    "        freqs = fftfreq(adjusted_output_dim, ts)[:adjusted_output_dim//2]\n",
    "        plt.ylabel('Magnitude')\n",
    "        plt.title('Frequency Domain Comparison')\n",
    "        plt.xlim([0, 50])  # Focus on relevant ECG frequencies\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Finished!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION METRICS\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,1800) (100,1792) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[32m     48\u001b[39m real_samples = X_dataset[:num_samples]\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m metrics = \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuality Metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m metrics.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcalculate_metrics\u001b[39m\u001b[34m(real_data, generated_data)\u001b[39m\n\u001b[32m      7\u001b[39m metrics = {}\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 1. Mean Squared Error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m mse = np.mean((\u001b[43mreal_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_data\u001b[49m) ** \u001b[32m2\u001b[39m)\n\u001b[32m     11\u001b[39m metrics[\u001b[33m'\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m'\u001b[39m] = mse\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 2. Pearson Correlation\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (100,1800) (100,1792) "
     ]
    }
   ],
   "source": [
    "# ========== EVALUATION METRICS ==========\n",
    "from scipy.stats import pearsonr, wasserstein_distance as wd\n",
    "from scipy.signal import correlate\n",
    "\n",
    "def calculate_metrics(real_data, generated_data):\n",
    "    \"\"\"Calculate various metrics to evaluate ECG quality\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Mean Squared Error\n",
    "    mse = np.mean((real_data - generated_data) ** 2)\n",
    "    metrics['MSE'] = mse\n",
    "    \n",
    "    # 2. Pearson Correlation\n",
    "    corr, _ = pearsonr(real_data.flatten(), generated_data.flatten())\n",
    "    metrics['Pearson_Correlation'] = corr\n",
    "    \n",
    "    # 3. Mean Absolute Error\n",
    "    mae = np.mean(np.abs(real_data - generated_data))\n",
    "    metrics['MAE'] = mae\n",
    "    \n",
    "    # 4. Dynamic Time Warping distance (simplified)\n",
    "    from scipy.spatial.distance import euclidean\n",
    "    dtw_dist = euclidean(real_data.flatten(), generated_data.flatten())\n",
    "    metrics['DTW_Distance'] = dtw_dist\n",
    "    \n",
    "    # 5. Frequency domain similarity\n",
    "    fft_real = np.abs(fft(real_data.flatten()))\n",
    "    fft_gen = np.abs(fft(generated_data.flatten()))\n",
    "    freq_similarity = pearsonr(fft_real, fft_gen)[0]\n",
    "    metrics['Frequency_Similarity'] = freq_similarity\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Generate samples for evaluation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "generator.eval()\n",
    "num_samples = 100\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_samples, noise_dim).to(device)\n",
    "    generated_samples = generator(noise).cpu().numpy()\n",
    "    # Denormalize\n",
    "    generated_samples = (generated_samples + 1) / 2 * (X_max - X_min) + X_min\n",
    "\n",
    "# Calculate metrics\n",
    "real_samples = X_dataset[:num_samples]\n",
    "metrics = calculate_metrics(real_samples, generated_samples)\n",
    "\n",
    "print(\"Quality Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value:.6f}\")\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\nStatistical Comparison:\")\n",
    "print(f\"  Real data - Mean: {real_samples.mean():.4f}, Std: {real_samples.std():.4f}\")\n",
    "print(f\"  Generated - Mean: {generated_samples.mean():.4f}, Std: {generated_samples.std():.4f}\")\n",
    "\n",
    "# Visualize multiple generated samples\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(t, generated_samples[i], label='Generated', alpha=0.7, linewidth=0.8)\n",
    "    plt.plot(t, real_samples[i], label='Real', alpha=0.5, linewidth=0.8)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Sample {i+1}')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.hist(real_samples.flatten(), bins=50, alpha=0.5, label='Real', density=True)\n",
    "plt.hist(generated_samples.flatten(), bins=50, alpha=0.5, label='Generated', density=True)\n",
    "plt.xlabel('Amplitude')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saving models...\")\n",
    "torch.save({\n",
    "    'generator': generator.state_dict(),\n",
    "    'discriminator': discriminator.state_dict(),\n",
    "    'g_optimizer': g_optimizer.state_dict(),\n",
    "    'd_optimizer': d_optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'metrics': metrics\n",
    "}, 'ecg_wgan_gp_model.pth')\n",
    "print(\"Models saved to: ecg_wgan_gp_model.pth\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fae87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-wsl2-conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
